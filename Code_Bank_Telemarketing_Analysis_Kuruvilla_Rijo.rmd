---
title: "Kuruvilla Rijo MA5810 Capstone"
author: "Rijo"
date: '2022-12-08'
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
getwd() # Get the current work directory
setwd('C:/Users/akila/Documents/DS_Masters_R/Introduction to Data Mining') # set the working directory

# Check the version of the R-studio
RStudio.Version()
```

# Load the libraries
```{r}
library(naivebayes)
library(caTools)
library(caret)
library(MASS)
library(cluster)
library(corrplot)
library(dbscan)
library(tidyverse)
library(car)
library(ggplot2)
library(ROCR)

```

# Load the data
```{r}

bank = read.csv("bank.csv",header = T ,sep = ';') # Load the data 
str(bank) # structure of the data 
summary(bank) # summary statistics of the data 
#View(bank)

# Converting columns to factor
column_names = c('job','marital','education','default','housing','loan','contact','month','poutcome','y')
bank[,column_names] = lapply(bank[,column_names],factor)
str(bank)


# Rename the variable term deposit
bank = plyr::rename(bank, c(y = "term_deposit"))
str(bank)

# Check for missing values
any(is.na(bank))

# Frequency of the Response Vairable ( Term Deposit)
ggplot(bank, aes(x= term_deposit)) +
geom_bar(fill='red') +  labs(x='Term Deposit') + ggtitle("Term Deposit Frequency Count")

# Frequency count of the response variable
bank %>% count(term_deposit)

```


# Eliminating the following variables for further analysis
'pdays' - There are lots of '-1' value (82.12 %) of the data , possibly indicating that the customers haven't been contacted for a long time. This can hinder the analysis , because it can be considered as missing data. therefore, this column has been removed.

```{r}
#Removing 'pdays' by subsetting the data
bank = dplyr::select(bank, -(pdays))
str(bank)
```


# Feature selection using Logistic Regression
```{r}

# Data Partioning
set.seed(1) # Set the seed for model consistency 
sample = sample.split(bank$term_deposit, SplitRatio = .80) # Split the data 
bank_train = subset(bank, sample == TRUE) # Training data 
bank_test = subset(bank, sample == FALSE) # Test data
dim(bank_train) # Dimensions of train data
dim(bank_test)  # Dimensions of test data

# Logistic Regression on training data 
lr_bank = glm(formula = term_deposit ~ . , data = bank_train , family = binomial)   
summary(lr_bank)  # Summary of the logistic regression model

# Check the VIF of the model 
vif(lr_bank)

# Comments:
#The variance inflation factor (VIF), which measures the correlation and strength of correlation between predictor variables in a regression model, was used to detect multicollinearity. A VIF greater than 10 indicates high collinearity, while a VIF between 5 and 10 necessitates additional investigation. On running the model on the whole data, most of the variables show a very low GVIF, indicating low collinearity, thereby satisfying the assumptions of the logistic REGRESSION 


# Using the backward logistic regression for feature selection
# BACKWARD LOGISTIC REGRESSION
stepwise_backward_lr = step(lr_bank, direction = "backward") # Applying the backward stepwise method 
summary(stepwise_backward_lr)  # summary of the stepwise method

# vif on stepwise backward lr
vif(stepwise_backward_lr)

# BOTH (FORWARD + BACWARD LOGISTIC REGRESSION) to double-check the backward regression results
step_lr_b = step(lr_bank, direction = "both")   
summary(step_lr_b)  # summary of the model

```

The model summary demonstrated that there was a decrease in AIC values from 1807 to 1796.8, demonstrating that the stepwise regression model was better and correctly extracted the essential features.

The following variables were identified as significant variables using p-values :
marital + housing + loan + contact + month + duration  + poutcome


# Logistic Regression using the selected features
```{r}
# Subset the data for selecting the features

bank_new = dplyr::select(bank, marital,housing,loan,contact,month,duration,poutcome,term_deposit) # subset the data using selected features


# # Split the data 
# set.seed(1)
# sample = sample.split(bank_new$term_deposit, SplitRatio = .80)
# bank_train = subset(bank_new, sample == TRUE)
# bank_test = subset(bank_new, sample == FALSE)
# dim(bank_train)
# dim(bank_test)

# Apply the Logistic Regression classifier on training data
log_reg_bank = glm(formula = term_deposit ~ . , data = bank_train , family = binomial)
summary(log_reg_bank)

# Prediction - on test data
pred_bank = predict(log_reg_bank, bank_test , type = "response")

# Set a prediction class
pred_class_bank = as.factor(ifelse(pred_bank > 0.5, 'yes','no'))

# Confusion matrix - Logistic Regression
confusionMatrix(pred_class_bank , bank_test$term_deposit) 

# contingency table
(tab_lr = table(pred_class_bank , bank_test$term_deposit))

# Accuracy
(accuracy_log_reg = sum(diag(tab_lr))/sum(tab_lr)*100)

# ROC PLOT - LOGISTIC REGRESSION 
pred_roc_log_reg = prediction(pred_bank , bank_test$term_deposit)  
perf = performance(pred_roc_log_reg, "tpr", "fpr")
plot(perf, col = "red", main="ROC curve - Logistic Regression ", xlab= "Specificity", ylab="Sensitivity")
abline(0, 1)
  
# Area under the curve
(auc_log_reg = performance(pred_roc_log_reg, "auc")@y.values)
```


# LOG REG WITH N - REPS
```{r}

for (i in 1:10)
{
  
 sample = sample.split(bank_new$term_deposit, SplitRatio = .80)
 bank_train = subset(bank_new, sample == TRUE)
 bank_test = subset(bank_new, sample == FALSE)
 dim(bank_train)
 dim(bank_test)

 # Apply the Logistic Regression classifier on training data
 log_reg_bank = glm(formula = term_deposit ~ . , data = bank_train , family = binomial)
 summary(log_reg_bank)

 # Prediction - on test data
 pred_bank = predict(log_reg_bank, bank_test , type = "response")

 # Set a prediction class
 pred_class_bank = as.factor(ifelse(pred_bank > 0.5, 'yes','no'))

 # Confusion matrix - Logistic Regression
 confusionMatrix(pred_class_bank , bank_test$term_deposit) 

 # contingency table
 tab_lr = table(pred_class_bank , bank_test$term_deposit)

 # Accuracy
 #accuracy_log_reg_n = sum(diag(tab_lr))/sum(tab_lr)
 accuracy_log_reg_n[i] = sum(diag(tab_lr))/sum(tab_lr)
 
}

print(round(accuracy_log_reg_n,4)*100)   # Average accuracy of the Model
#print(sd(accuracy_qda_n)) # Standard Deviation of the model

sprintf("Log Reg  -  Average Accuracy : %s",
        mean(round(accuracy_log_reg_n,4)*100))

sprintf("Standard Deviation Logistic Regression : %s",
        sd(accuracy_log_reg_n))

```

# Naive Bayes Classification

# Validating the assumptions of Naive Bayes classifer
Using the chi-squared test of independence to determine the association between the categorical variables

# State the Null and Alternate Hypothesis
H0: Significant relationship does not exist between the predictors and response
Ha: Significant relationship exists between the predictors and response 

```{r}

bank_new = dplyr::select(bank, marital,housing,loan,contact,month,duration,poutcome,term_deposit)
str(bank_new)

# Performing the chi-square test of independence on the predictor variables
lapply(bank_new[,-c(8)], function(x) chisq.test(table(x,bank$term_deposit), simulate.p.value = TRUE))

0.0004998 < 0.05

# For numerical variable - Plot the histogram
par(mfrow  = c(1,2))
hist(bank_new$duration, col = "red", xlab = "Duration",main = "Contact Duration - Histogram (Before Transformation)")
hist(log(bank_new$duration), col = "green" , xlab = "Duration", main = "Contact Duration - Histogram (After Transformation)") # Using Log- Transformation to normalize the duration variable

```
Comments : #Since all p-values (0.0004998) < 0.05. Therefore Ha is true, significant relationship exists between the predictors and response variable


# Naive Bayes Classifier
```{r}
# Split the data 
set.seed(1) # set seed to ensure consistency 
sample = sample.split(bank_new$term_deposit, SplitRatio = .80) # Split the data 
bank_train = subset(bank_new, sample == TRUE) # Training data 
bank_test = subset(bank_new, sample == FALSE) # Test data
dim(bank_train) # Dimensions of train data 
dim(bank_test) # Dimenstions of test data

# Build the model on the training data
nb_bank = naive_bayes(term_deposit ~ . , data = bank_train, usekernel = TRUE)  # Train the model
summary(nb_bank) # summary of the naive bayes classifier 

nb_bank$tables # To extract each columns summary

# Naive Bayes Visualization
par(mfrow = c(1,3), mar = c(4,4,1,1))
plot(nb_bank , which = 1:3) # First 3 variables
par(mfrow = c(1,1))

par(mfrow = c(1,4), mar = c(4,4,1,1))
plot(nb_bank , which = 4:7) # Last  4 variables
par(mfrow = c(1,1))


# Prediction on the test data
pred_nb_bank = predict(nb_bank, bank_test[,-c(8)]) 

#Confusion Matrix - Naive Bayes 
confusionMatrix(table(pred_nb_bank,bank_test$term_deposit))


# NAIVE BAYES Accuracy 
tab_nb_bank = table(pred_nb_bank,bank_test$term_deposit)
accuracy_nb_bank = sum(diag(tab_nb_bank))/sum(tab_nb_bank)

print((round(accuracy_nb_bank,4)*100))   # Accuracy of the Model

round(sd(accuracy_nb_bank),2) # Standard Deviation of the model


```

# Naive Bayes model - With Kernel - N-REPS
```{r}
# Naive Bayes model - N-REPS
for(i in 1:10)
{
  #set.seed(123)
  sample = sample.split(bank_new$term_deposit, SplitRatio = .80)
  bank_train = subset(bank_new, sample == TRUE)
  bank_test = subset(bank_new, sample == FALSE)
  
  #?naivebayes
  
  nb_bank = naive_bayes(term_deposit ~ . , data = bank_train, usekernel = TRUE)  # Train the model
  pred_nb_bank = predict(nb_bank, bank_test[,-c(8)]) # Prediction on the test data
  
  #Confusion Matrix - Naive Bayes
  confusionMatrix(table(pred_nb_bank,bank_test$term_deposit))
  
  # NAIVE BAYES Accuracy - WITH KERNEL
  tab_nb_bank = table(pred_nb_bank,bank_test$term_deposit)
  #accuracy_nb_bank_n = sum(diag(tab_nb_bank))/sum(tab_nb_bank)
  accuracy_nb_bank_n[i] = sum(diag(tab_nb_bank))/sum(tab_nb_bank)
}
print((round(accuracy_nb_bank_n,4)*100))   # Accuracy of the Model

sprintf("NB mean accuracy: %s",mean(round(accuracy_nb_bank_n,4)*100))  # Average accuracy of the Model

```

# # Naive Bayes model Without Kernel  - N-REPS
```{r}
# Naive Bayes model - N-REPS
for(i in 1:10)
{
  #set.seed(123)
  sample = sample.split(bank_new$term_deposit, SplitRatio = .80)
  bank_train = subset(bank_new, sample == TRUE)
  bank_test = subset(bank_new, sample == FALSE)
  
  #?naivebayes
  
  nb_bank = naive_bayes(term_deposit ~ . , data = bank_train)  # Train the model
  pred_nb_bank = predict(nb_bank, bank_test[,-c(8)]) # Prediction on the test data
  
  #Confusion Matrix 
  confusionMatrix(table(pred_nb_bank,bank_test$term_deposit))
  
  # NAIVE BAYES Accuracy - WITHOUT KERNEL
  tab_nb_bank = table(pred_nb_bank,bank_test$term_deposit)
  #accuracy_nb_bank_n_2 = sum(diag(tab_nb_bank))/sum(tab_nb_bank)
  accuracy_nb_bank_n_2[i] = sum(diag(tab_nb_bank))/sum(tab_nb_bank)
}
print((round(accuracy_nb_bank_n_2,4)*100))   # Accuracy of the Model

sprintf("NB mean accuracy: %s",mean(round(accuracy_nb_bank_n_2,4)*100))  # Average accuracy of the Model

```


# Comparison of Accuracies and Standard Deviations of all classifiers
```{r}

# Comparision of accuracy results of all classifiers 
overall_accuracy = round(c(mean(accuracy_nb_bank_n),mean(accuracy_log_reg_n)),digits = 4)*100
accuracy_results = as.data.frame(rbind(overall_accuracy))
names(accuracy_results)= c("Naive Bayes Classifier", "Logistic Regression Classifier")
print(accuracy_results)
#View(accuracy_results)


# Comparison of Standard Deviation of all classifiers
overall_sd = round(c(sd(accuracy_nb_bank_n),sd(accuracy_log_reg_n)),digits = 5)
sd_results = as.data.frame(rbind(overall_sd))
names(sd_results)=c("Std. Deviation - Naive Bayes", "Std. Deviation Logistic Regression ")
print(sd_results)
#View(sd_results)

```

# Comments:

Logistic Regression and Naive Bayes classifiers both produce high-accuracy results.Logistic Regression had the highest accuracy score of 89.16%, while Nave Bayes had the lowest at 84.29%. Both classifiers were replicated ten times with a for loop, and their accuracy means, and standard deviation means were calculated across ten test sets. The mean accuracy scores for Logistic Regression and Naive Bayes classifiers were 90.15% and 89.98%, with mean standard deviations of 0. 0.00845 and 0.00704, respectively. TABLE 3 displays the confusion matrix, which aids in determining the model's accuracy results. The rows represent what the algorithm predicted, while the columns represent the actual results.
Logistic Regression correctly classifies 782 (True Positives) of 800 "no" subscriptions while incorrectly classifying 80 (True Negatives) of 104 "yes" subscriptions. The Naive Bayes model correctly categorizes 756 of 800 "no" subscriptions while incorrectly categorizing 98 (False Positives) of 104 "yes" subscriptions.

The Area under the Receiver Operating Characteristic Curve (AUC-ROC) was also plotted to evaluate the classifier's performance, as shown in FIGURE 3, which displays the accuracy results of Logistic Regression. The ROC curve is formed by changing the classification probability and plotting the True Positive rate vs the False Positive Rate. The red diagonal line corresponds to a pure random allocation of class labels. Values close to 0.5 indicate performance comparable to random, while values less than 0.5 indicate performance worse than random. AUC values closer to one indicate that the classifier performs better. AUC-ROC also works best for imbalanced data and hence is ideal for this dataset. AUC-ROC for the logistic regression is 89.43% which indicates a good model performance in determining the response variable.

# Hierarchical Clustering
As the dataset consists of a mixture of categorical and numerical data, hierarchical clustering is the technique used to validate the best separation of classes. K-means clustering cannot be used on the output of daisy function. K-means cannot cluster the data on the basis of distance matrix.Therefore only Hierarchical clustering can be used

# Dissimilarity measure : GOWERS
```{r}

# Check the variance of the numerical variables
var(bank_new[,6])

# save the response column in a separate variable
term_deposit = bank_new[,8]

# standardizing(Scaling) the numerical variables 
duration = scale(bank_new$duration)


# Merge the scaled data and response variable to a new dataframe
bank_new_2 = cbind(bank_new[,c(1,2,3,4,5,7)],duration,term_deposit)
str(bank_new_2)

# Recheck the variance
var(bank_new_2[,7])

# Using the gowers distance as the data is a mixture of categorical and numerical
gowers_distance_bank = daisy(bank_new_2[,-c(8)] , metric = "gower")
summary(gowers_distance_bank)

# Convert to matrix view the distances
gowers_bank = as.matrix(gowers_distance_bank)  # Dissimilarity matrix 
similarity_bank = 1 - gowers_bank

```


# AHC - Agglomerative Hierarchical Clustering 
```{r}
ahc_single = hclust(gowers_distance_bank , method = "single")  # Hclust using single linkage
ahc_complete = hclust(gowers_distance_bank , method = 'complete')  # Hclust using complete linkage
ahc_average = hclust(gowers_distance_bank , method = 'average') # Hclust using average linkage
ahc_wards = hclust(gowers_distance_bank , method = 'ward.D2')  # Hclust using wards linkage


# Plot the dendogram
par(mfrow = c(2,2))
plot(ahc_single, main = "Single Linkage Dendrogram", xlab = "", sub = "", hang = -1, col = "red")
plot(ahc_complete, main = "Complete Linkage Dendrogram", xlab = "", sub = "", hang = -1, col = "green")
plot(ahc_average, main = "Average Linkage Dendrogram", xlab = "", sub = "", hang = -1, col = "blue")
plot(ahc_wards, main = "Wards Distance Dendrogram", xlab = "", sub = "", hang = -1, col = "brown")


## Tree cutting in Hierarchical clustering 

# cutting the tree into 2 cluster's 
ahc_single_linkage_cut = cutree(ahc_single,2) # Single Linkage Cut
ahc_complete_linkage_cut = cutree(ahc_complete,  k = 2) # Complete Linkage cut
ahc_average_linkage_cut = cutree(ahc_average,  k = 2)  # Average Linkage cut
ahc_wards_cut<-cutree(ahc_wards,  k = 2) # Wards linkage cut
 
# show the cut
ahc_single_linkage_cut   # cut- single linkage 
ahc_complete_linkage_cut  # cut - complete linkage 
ahc_average_linkage_cut   # cut - average linkage
ahc_wards_cut             # cut - wards distance

```


# Hull Plots for AHC
To plot Hull Plots, all predictors should be numerical, therefore all predcitors were converted to numerical datatype before plotting the hullplots.
```{r}

bank_new_3 <- data.frame(lapply(bank_new_2, as.numeric), stringsAsFactors=FALSE) # convert factor variables to numeric

bank_new_3 = cbind(duration , bank_new_3)  # column bind to a new data frame
str(bank_new_3)

# Using the gowers distance as the data is a mixture of categorical and numerical
gowers_distance_bank_2 = daisy(bank_new_2[,-c(8)], metric = "gower")
summary(gowers_distance_bank_2)

# Convert to matrix view the distances
gowers_bank_2 = as.matrix(gowers_distance_bank_2)  # Dissimilarity matrix 
similarity_bank_2 = 1 - gowers_bank_2

# Linkages
ahc_single_2 = hclust(gowers_distance_bank_2 , method = "single")  # Hclust using single linkage
ahc_complete_2 = hclust(gowers_distance_bank_2 , method = 'complete')  # Hclust using complete linkage
ahc_average_2 = hclust(gowers_distance_bank_2 , method = 'average') # Hclust using average linkage
ahc_wards_2 = hclust(gowers_distance_bank_2 , method = 'ward.D2')  # Hclust using wards linkage

## Tree cutting in Heirarchical clustering 

# cutting the tree into 2 cluster
ahc_single_linkage_cut_2 = cutree(ahc_single_2,2)
ahc_complete_linkage_cut_2 = cutree(ahc_complete_2,  k = 2)
ahc_average_linkage_cut_2 = cutree(ahc_average_2,  k = 2)
ahc_wards_cut_2 = cutree(ahc_wards_2,  k = 2)

# show the cut
ahc_single_linkage_cut_2   # cut- single linkage 
ahc_complete_linkage_cut_2  # cut - complete linkage 
ahc_average_linkage_cut_2   # cut - average linkage
ahc_wards_cut_2             # cut - wards distance


# Plot the Hull Plot
par(mfrow = c(2,2))
hullplot(bank_new_3[,-c(8)], cl = ahc_single_linkage_cut_2, col = "red", main = "Single Linkage - Hull Plot")

hullplot(bank_new_3[,-c(8)], cl = ahc_complete_linkage_cut_2, col = "black", main = "Complete Linkage - Hull Plot")
hullplot(bank_new_3[,-c(8)], cl = ahc_average_linkage_cut_2, col = "blue", main = "Average Linkage - Hull Plot")

hullplot(bank_new_3[,-c(8)], cl = ahc_wards_cut_2, col = "brown", main = "Wards Linkage - Hull Plot")

```

# Combined Dendrogram and HUll plot for wards distance
```{r}
par(mfrow = c(1,2))
plot(ahc_wards, main = "Wards Distance Dendrogram", xlab = "", sub = "", hang = -1, col = "brown") # Dendrogram
hullplot(bank_new_3[,-c(8)], cl = ahc_wards_cut, col = "brown", main = "Wards Linkage - Hull Plot") # Hull Plot

```

# Comments:
Clustering was used to cross-check the results of the naive Bayes and logistic regression classifier and to check if there are more natural clusters as compared to the original two classes.
FIGURE 4 depicts the dendrograms for all types of linkages used to determine clustering results. Dendrograms are excellent visualizing structures, and the key to understanding them is to concentrate on the height at which any two objects are joined together. Each dendrogram leaf represents an observation. As we climb the tree, the observations of each mother merge into branches. As we climb the tree, the branches join together with leaves or other branches. This fusion's vertical axis height indicates how different the two observations are. Thus, observations fusing near the bottom of the tree are very similar, whereas observations fusing near the top of the tree are very different.
